{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2번.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNdzhrh+p3c7VdIrcABbGJD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pqR6V5QVOmO9"},"source":["from sklearn.datasets import fetch_openml\n","import sklearn\n","import csv\n","### data 로드 ###\n","mnist = fetch_openml('mnist_784')\n","#print(sklearn.__version__)\n","#!pip install scikit-learn==0.24.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqDTM-cqmqbC"},"source":["\n","### data 일부만 추출하는 과정 ###\n","def extract_data(dataset, name = 'mnist',ratio = 0.1):\n","    data_list = dataset['data']\n","    label_list = dataset['target']\n","    ratio = (1-ratio)\n","    test_data = data_list[int(data_list.shape[0]*ratio):,]\n","    test_label = label_list[int(label_list.shape[0]*ratio):,]\n","    return test_data, test_label\n","\n","test_data, test_label = extract_data(mnist)\n","\n","dic = {}\n","for label in test_label:\n","  if label not in dic:\n","    dic[label]=0\n","  dic[label]+=1\n","print(dic)\n","print(len(test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"59AIu6o4Ona2"},"source":["import numpy as np\n","import copy\n","import matplotlib.pyplot as plt\n","import sys\n","\n","### 거리 메소드 ###\n","### 1번과 다르게 mahalanobis는 너무 오래걸려서 뺐다 ###\n","def euclidean(x,center):\n","    return ((x - center)**2).sum(axis=1)\n","    \n","### 초기화 메소드 ###\n","### 1번과 동일하게 작성 ###\n","def random_initialize(k, data, dim):\n","    centers = []\n","    for i in range(dim):\n","      centers.append(np.random.randint(np.min(data), np.max(data), size = k))\n","    return np.array(centers)\n","\n","def eff_initialize(k, data, dim, label):\n","    visit = set()\n","    label_visit = set()\n","    centers = np.zeros((k,dim))\n","    temp = copy.deepcopy(data.T)\n","    i = np.random.randint(0,temp.shape[0],size=1)\n","    i = int(i)\n","    visit.add(i)\n","    centers[0] = temp[i]\n","    label_visit.add(label[i])\n","    while len(visit)<k:\n","        _next = np.argmax(((temp-temp[i])**2).sum(axis=1))\n","        if _next not in visit and label[_next] not in label_visit:\n","          centers[len(visit)] = temp[_next]\n","          visit.add(_next)\n","          label_visit.add(label[_next])\n","          i=_next\n","        else:\n","          temp[_next] = temp[i]\n","    return centers\n","\n","### 1번과 동일하게 kmeans 작성 ###\n","def kmeans(k, dim, img, label, init='eff_initialize', distance_method = 'euclidean'):\n","    data = img.reshape(-1,dim).T ### dim, -1\n","    ### initialize ###\n","    centers = []\n","    \n","    if init=='random_initialize':\n","        centers = random_initialize(k, data, dim) ### nan 떠서 안됌\n","    elif init=='eff_initialize':\n","        centers = eff_initialize(k,data, dim, label)\n","    if distance_method=='euclidean':\n","        method = euclidean\n","    \n","    pre_centers = copy.deepcopy(centers)\n","    while True:\n","        distances = []\n","        center_distance = {i:[] for i in range(k)}\n","        out = []\n","        for i,center in enumerate(centers):\n","            distance = method(data.T, center) # 원소개수, 센터개수\n","            out.append(distance)\n","        distances = np.array(out)\n","        \n","        outputs = {i:[] for i in range(10)}\n","        centers = []\n","        candidates = np.argmin(distances,axis=0)\n","        for _k in range(k):\n","            centers.append(data[:,np.where(candidates==_k)[0]].mean(axis=1))\n","            outputs[_k].append(np.where(candidates==_k)[0])\n","        centers = np.array(centers).squeeze()\n","        \n","        #print(centers.shape) # 10,784\n","        \n","        if (pre_centers-centers).sum()==0:\n","            break\n","        pre_centers = copy.deepcopy(centers)\n","    return centers, outputs\n","\n","### accuracy 메소드 작성 ###\n","def accuracy(preds, targets):\n","  targets = np.array(list(map(int,targets))) ### str -> int로 바꾸기\n","  preds = preds.astype('int')\n","  result = []\n","  for pred, target in zip(preds, targets):\n","    if pred==target:\n","      result.append(1)\n","    else:\n","      result.append(0)\n","  return sum(result)/len(result)\n","  \n","centers, outputs = kmeans(10, 784, test_data, test_label)\n","\n","'''\n","### kmeans 센터마다 아웃풋 출력과정\n","plt.figure(figsize=(5,5))\n","for pred, output in outputs.items():\n","  for idx in output[0]:\n","    plt.axis('off')\n","    plt.imshow(test_data[idx].reshape((28,28)).astype('uint8'), cmap='gray')\n","    plt.show()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"INWzClClOoK3"},"source":["import numpy as np\n","import copy\n","from tqdm import tqdm\n","\n","### gradient 계산하는 메소드 ###\n","def gradient_calculate(img,k):\n","  dy_filter = np.array([[-1,-2,-1],[0,0,0],[1,2,1]]) # dy 필터생성\n","  dx_filter = np.array([[-1,0,1],[-2,0,2],[-1,0,1]]) # dx 필터생성\n","  img = img.reshape((28,28))\n","  img = np.pad(img, ((1,1),(1,1)),'constant', constant_values=0) # 패딩작업\n","  divide_height = img.shape[0]//k # 나누고 난뒤 높이\n","  divide_width = img.shape[1]//k # 나누고 난뒤 너비\n","  feature = []\n","  for h in range(k):\n","    for w in range(k):\n","      \n","      divide_img = copy.deepcopy(img[h*divide_height:(h+1)*divide_height, w*divide_width:(w+1)*divide_width])\n","      orientation_dic = {i:0 for i in np.arange(-np.pi,np.pi,np.pi/4)} # 8 dim을 만들기 위해서\n","      dims = sorted(orientation_dic.keys())\n","      for i in range(1,divide_img.shape[0]-1):\n","        for j in range(1, divide_img.shape[1]-1):\n","          ### dy, dx 계산하고 orientation, magnitude 구하는 과정 ###\n","          dy = (divide_img[i-1:i+2,j-1:j+2]*dy_filter).sum()\n","          dx = (divide_img[i-1:i+2, j-1:j+2]*dx_filter).sum()\n","          magnitude = (dy**2 + dx**2)**(1/2)\n","          orientation = np.arctan(dy/(dx+1e-8))\n","          for idx in range(len(dims)-1):\n","            ### 해당 orientation 반올림 하는 과정 ###\n","            if dims[idx]<=orientation<dims[idx+1]:\n","              if abs(dims[idx]-orientation) < abs(dims[idx+1]-orientation):\n","                orientation_dic[dims[idx]]+=magnitude\n","              else:\n","                orientation_dic[dims[idx+1]]+=magnitude\n","              break\n","      \n","      for key,value in sorted(orientation_dic.items(), key=lambda x: x[0]):\n","        feature.append(value)\n","  \n","  return feature\n","\n","### 해당 features 만드는 과정 -> 8 x 4 feature 7000개\n","features = []\n","for img in tqdm(test_data): # 실행과정 볼려고 tqdm 사용함\n","  feature = gradient_calculate(img,2)\n","  features.append(feature)\n","features = np.array(features)\n","'''\n","### 히스토그램 출력하는 과정이므로 주석처리 ###\n","for img in test_data:\n","  feature = gradient_calculate(img,2)\n","  a,b,c,d = np.array(feature).reshape(4,8)\n","  plt.bar(np.arange(len(a)),a)\n","  plt.show()\n","  plt.bar(np.arange(len(a)),b)\n","  plt.show()\n","  plt.bar(np.arange(len(a)),c)\n","  plt.show()\n","  plt.bar(np.arange(len(a)),d)\n","  plt.show()\n","  features.append(feature)\n","  break\n","'''\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VN7fSD5TOxNT"},"source":["'''\n","### 8 x 4 features 로 kmeans 한 결과 출력하는 과정이므로 주석처리 ###\n","centers, outputs = kmeans(10, 32, np.array(features), test_label)\n","\n","plt.figure(figsize=(35,30))\n","for _, output in outputs.items():\n","  \n","  for idx in output[0]:\n","    plt.axis('off')\n","    plt.imshow(test_data[idx].reshape((28,28)).astype('uint8'), cmap='gray')\n","\n","    plt.show()\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-t5fr6lQQZXq"},"source":["### pytorch 이용해서 Lenet 만드는 과정 ###\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class Net(nn.Module):\n","\n","    def __init__(self): # 초기화 진행 -> conv와 fc 만듬, dp는 overfit을 목적으로 만들었기에 필요없음\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 6, 5)\n","        self.conv2 = nn.Conv2d(6, 16, 3)\n","        self.conv3 = nn.Conv2d(16, 120, 3)\n","        self.fc1 = nn.Linear(120 * 3 * 3, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","        self.pool = nn.AvgPool2d(2)\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x):\n","        x = self.pool(self.tanh(self.conv1(x)))\n","        x = self.pool(self.tanh(self.conv2(x)))\n","        x = self.tanh(self.conv3(x))\n","        \n","        x = x.view(-1, 120*3*3) # 차원 맞춰줘야 되므로 reshape 과정\n","\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","def train(model, data, target):\n","  \n","  model = model.cuda()\n","  model.train()\n","  optimizer = optim.SGD(model.parameters(), lr=0.1) # optimize는 SGD\n","  scheduler = optim.lr_scheduler.StepLR(optimizer,20) # 혹시나를 위해서 scheduler 설정\n","  criterion = nn.CrossEntropyLoss() # multi-class 이므로 crossentropy loss 사용\n","  losses = []\n","  scores = []\n","  for epoch in range(100):\n","    running_loss = 0\n","    inputs = []\n","    labels = []\n","    preds = []\n","    targets = []\n","    for input, label in zip(data,target):\n","      if len(inputs)!=4: # batch단위로 묶는 과정\n","        inputs.append(input)\n","        labels.append(int(label))\n","        continue\n","      inputs = torch.tensor(inputs,dtype=torch.float).reshape(4,1,28,28).cuda() # expand dim해서 conv와 차원을 맞춰준다.\n","      inputs = inputs/255. # normalize 하는 과정 -> 혹시나의 nan, inf 등의 floating error를 위하여\n","      \n","      labels = torch.tensor(labels).cuda()\n","      outputs = net(inputs)\n","      \n","      \n","      loss = criterion(outputs, labels)\n","      optimizer.zero_grad()\n","      loss.backward() # gradient 계산\n","      optimizer.step() # update model's weights\n","      \n","      for output, label in zip(torch.argmax(torch.softmax(outputs,dim=1), dim=1), labels): # softmax를 이용해서 predition을 한다\n","          preds.append(output.item())\n","          targets.append(label.item())\n","      running_loss += loss.item()\n","      inputs = []\n","      labels = []\n","    # loss와 score 출력하는 과정\n","    preds = np.array(preds)\n","    targets = np.array(targets)\n","    score = (preds==targets).sum()/len(preds)\n","    losses.append(running_loss/len(data))\n","    scores.append(score)\n","    print('epoch : {}, loss : {}, score : {}'.format(epoch, running_loss/len(data), score))\n","    scheduler.step()\n","    if score==1:\n","      x_axis = np.arange(len(losses))\n","      plt.plot(x_axis,losses)\n","      x_axis = np.arange(len(scores))\n","      plt.plot(x_axis,scores)\n","      break\n","  return model\n","net = Net()\n","#summary(net, (1,28,28), device='cpu')\n","model = train(net, test_data, test_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4swGi6-jdOo_"},"source":["### 784 dim으로 진행 ###\n","centers, outputs = kmeans(10, 784, test_data, test_label)\n","i=0\n","total_accuracy = 0\n","x_axis = []\n","y_axis = []\n","for pred, output in outputs.items():\n","  center_preds = {i:0 for i in range(10)}\n","  indexes = output[0]\n","  for idx in indexes:\n","    ### prediction -> labeling 하는 과정\n","    input = torch.tensor(test_data[idx], dtype=torch.float).reshape((1,1,28,28)).cuda()\n","    output = model(input)\n","    number = torch.argmax(output).item() # 어차피 제일 큰값이 softmax해도 크므로 할필요 없다 생각하고 argmax만 적용\n","    center_preds[number]+=1\n","  center_preds = sorted(center_preds.items(), key=lambda x:-x[1]) # 높게 나온 순으로 정렬\n","  label = center_preds[0][0] # 가장 앞에껄로 labeling\n","  accuracy = center_preds[0][1]/len(indexes) # accuracy 계산\n","  print('label : {}, accuracy : {}'.format(label, accuracy))\n","  total_accuracy += accuracy\n","  x_axis.append(str(label))\n","  y_axis.append(accuracy)\n","print('total score : {}'.format(total_accuracy/10))\n","helper = np.arange(len(x_axis))\n","plt.bar(helper, y_axis)\n","plt.xticks(ticks=helper, labels=x_axis)\n","plt.xlabel('labels')\n","plt.ylabel('Accuracy')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3G5YlKnpONoW"},"source":["### 784 dim으로 진행 ###\n","features = np.array(features)\n","centers, outputs = kmeans(10, 32, features, test_label)\n","i=0\n","total_accuracy = 0\n","x_axis = []\n","y_axis = []\n","for pred, output in outputs.items():\n","  center_preds = {i:0 for i in range(10)}\n","  indexes = output[0]\n","  for idx in indexes:\n","    ### prediction -> labeling 하는 과정, 위 784로 했을때와 동일\n","    input = torch.tensor(test_data[idx], dtype=torch.float).reshape((1,1,28,28)).cuda()\n","    output = model(input)\n","    number = torch.argmax(output).item()\n","    center_preds[number]+=1\n","  center_preds = sorted(center_preds.items(), key=lambda x:-x[1])\n","  label = center_preds[0][0]\n","  accuracy = center_preds[0][1]/len(indexes)\n","  print('label : {}, accuracy : {}'.format(label, accuracy))\n","  total_accuracy += accuracy\n","  x_axis.append(str(label))\n","  y_axis.append(accuracy)\n","print('total score : {}'.format(total_accuracy/10))\n","helper = np.arange(len(x_axis))\n","plt.bar(helper, y_axis)\n","plt.xticks(ticks=helper, labels=x_axis)\n","plt.xlabel('labels')\n","plt.ylabel('Accuracy')\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}